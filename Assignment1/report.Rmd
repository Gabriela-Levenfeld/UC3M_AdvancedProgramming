---
title: "Advanced Programming"
author: "Errasti Dom√≠nguez, Nuria and Levenfeld Sabau, Gabriela"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 6
    keep_tex: yes
  geometry: left=3cm,right=3cm,top=2cm,bottom=2cm
  mathjax: local
  self_contained: no
  word_document:
    toc: yes
    toc_depth: '6'
subtitle: RCPP ASSIGNMENT, PROGRAMMING NEAREST NEIGHBOUR IN C++
font-family: Helvetica
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\pagebreak

# Preparing data

First of all, we must prepared the data we are going to work with.

```{r}
set.seed(123) # for reproducibility 

# X contains the inputs as a matrix of real numbers
data("iris")
iris_shuffled <- iris[sample(nrow(iris)), ]

# X contains the input attributes (excluding the class)
X <- iris_shuffled[,-5]
# y contains the response variable (named medv, a numeric value)
y <- iris_shuffled[,5]

# From dataframe to matrix
X <- as.matrix(X)
# From factor to integer
y <- as.integer(y)

# This is the point we want to predict
X0 <- c(5.80, 3.00, 4.35, 1.30)
```

\pagebreak
# Preliminare: my_knn_R

## R code

Here it is attached the knn function programmed in R language by the professor for the assignment that we will use during the task.

```{r}
my_knn_R = function(X, X0, y){
  # X data matrix with input attributes
  # y response variable values of instances in X  
  # X0 vector of input attributes for prediction (just one instance)
  
  nrows = nrow(X)
  ncols = ncol(X)
  
  distance = 0
  for(j in 1:ncols){
    difference = X[1,j]-X0[j]
    distance = distance + difference * difference
  }
  
  distance = sqrt(distance)

  closest_distance = distance
  closest_output = y[1]
  closest_neighbor = 1
  
  for(i in 2:nrows){
    
    distance = 0
    for(j in 1:ncols){
      difference = X[i,j]-X0[j]
      distance = distance + difference * difference
    }
    
    distance = sqrt(distance)
    
    if(distance < closest_distance){
      closest_distance = distance
      closest_output = y[i]
      closest_neighbor = i
    }
  }
  closest_output
}  
```

## Compile R code

```{r}
print(my_knn_R(X, X0, y))
```

\pagebreak
# Task 1: my_knn_c

## Translate R code into C++

```{Rcpp}
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
int my_knn_c(NumericMatrix X, NumericVector X0, IntegerVector y){
  /*
   - X data matrix with input attributes. Each row represent an observation and columns 
  are refer to the different varibles (features) we are having into account.
   - y response variable values of instances in X. Vector that contain the response
  varibles (3 possible values: setosa, versicolor or virginica)
  - X0 vector of input attributes for prediction (just one instance)
  */
  
  int nrows = X.nrow(); //number of observations
  int ncols = X.ncol(); //features or attributes that are being considered
  
  // Initialize variables for distance calculation
  double distance = 0;
  double difference = 0;
  int j;

  /* Compute Euclidean distance between the input instance X0 and the first row
  (observation) of X in order to initialize the parameter distance. */
  for (j=0; j<ncols; ++j){
    difference = X(1,j)-X0[j];
    distance = distance + difference * difference;
  }
  distance = sqrt(distance);
  
  /* Next step is to compute every distance between X0 and the observations of matrix X
  and store the lowest value in the closest_distance parameter. */
  double closest_distance = distance;
  double closest_output = y[1];
  int closest_neighbor = 1;
  int i;
  
  for (i=1; i<nrows; ++i){
    distance = 0;
    for (j=0; j<ncols; ++j){
      difference = X(i,j)-X0[j];
      distance = distance + difference * difference;
    }
    
    distance = sqrt(distance);
    
      /* Finally, we will return the output value of the closest neighbor based on
    the shortest distance. */
      if(distance < closest_distance){
        closest_distance = distance;
        closest_output = y[i];
        closest_neighbor = i;
      }
  }
  return closest_output;
}
```

## Compile C++ code with sourceCpp

```{r echo=TRUE, warning=FALSE, message=FALSE}
library(Rcpp)
sourceCpp('C:/Users/gabri/OneDrive - Universidad Carlos III de Madrid/Escritorio/Advanced Programming/Task1/task1_my_knn_c.cpp')
print(my_knn_c(X, X0, y))
```
We can observed that same result as before is achieved.

## Verify Results against FNN/class knn

```{r echo=TRUE, warning=FALSE, message=FALSE}
# Using class:knn to predict point X0
library(class)
print(class::knn(X, X0, y, k=1))
```

As we can observed the result is the same as with R code and C++ code, 2.

## Use microbenchmark to compare performance

```{r echo=TRUE, warning=FALSE, message=FALSE}
library(microbenchmark)
microbenchmark(my_knn_c(X, X0, y), my_knn_R(X, X0, y), knn(X, X0, y, k=1),
               times = 1000)
```

This information refers to the execution time of each knn function (R, C++ and class) express in microseconds.
We can verify that C++ implementation is much faster than the other two options, with a mean time of just 6.70 microseconds (which is significantly faster). To do so, we have set up the evaluation parameter into 1000 times, so we can estimate the execution time in a more reliable way.

\pagebreak
# Task 2: my_knn_c_euclidean

From this point onwards, we have created and loaded our own package (*rcppAssignment.Rproj*) which contains all function needed. The C++ code from all function can be found inside rcppAssignment/src/my_knn_c_function.cpp

# Task 3: my_knn_c_minkowsky
# Task 4